





import pandas as pd
from pathlib import Path
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)



# path of the dataset
path = Path("G:/Data Science/EDA/EDA-DataCamp-2025/datasets/ds_salaries_clean.csv")
# Load the dataset
salaries = pd.read_csv(path)


# See the quick summary of the dataset
salaries.info()


# Salary by experience level
sns.boxplot(data=salaries, x="Experience", y="Salary_USD", palette="tab10")
plt.show()


# checking for missing values
salaries.isna().sum()


# Dropping missing values
threshold = len(salaries) * 0.05
threshold


cols_to_drop = salaries.columns[salaries.isna().sum() <= threshold]
cols_to_drop











plane_path = Path("G:/Data Science/EDA/EDA-DataCamp-2025/datasets/planes.csv")
planes = pd.read_csv(plane_path)
planes.head(n=2)


planes.shape


# Print the number of missing values in each column of the DataFrame.
planes.isnull().sum()


# Calculate how many observations five percent of the planes DataFrame is equal to.
# Lets define a threshold
threshold = len(planes) * 0.05
threshold


# Create cols_to_drop by applying boolean indexing to columns of the DataFrame with missing values less than or equal to the threshold.
cols_to_drop = planes.columns[planes.isnull().sum() <= threshold]
cols_to_drop


# Use this filter to remove missing values and save the updated DataFrame.
planes.dropna(subset=cols_to_drop, inplace=True)


planes.isna().sum()








# Print the values and frequencies of "Additional_Info"
planes["Additional_Info"].value_counts()


# Create a boxplot of "Price" versus "Airline".
plt.figure(figsize=(12, 8))
sns.boxplot(data=planes, x="Airline", y="Price", palette="tab10")
plt.show()


# this is for my understanding about the price 
sns.boxplot(data=planes, x="Price")


# How should you deal with the missing values in "Additional_Info" and "Price"?
# Ans : Remove the "Additional_Info" column and impute the median by "Airline" for missing values of "Price"
planes.drop("Additional_Info", axis=1, inplace=True)








# Group planes by airline and calculate the median price.
airline_prices = planes.groupby("Airline")["Price"].median()
airline_prices


# Convert the grouped median prices to a dictionary.
prices_dict = airline_prices.to_dict()
prices_dict


# Conditionally impute missing values for "Price" by mapping values in the "Airline" column based on prices_dict.
planes["Price"] = planes["Price"].fillna(planes["Airline"].map(prices_dict))


# check final is there any null values in dataset
planes.isna().sum()





salaries.select_dtypes("object").head()


# Job titles
salaries["Designation"].value_counts()


# count unique job titles
salaries["Designation"].nunique()


salaries["Designation"]


# Extracting value from categories using pandas.Series.str.contains()
salaries["Designation"].str.contains("Scientist")



# Finding multiple phrases in string
salaries["Designation"].str.contains("Machine Learning|AI")


# Words on intreset: Any that start with data
salaries["Designation"].str.contains("^Data")


job_categories = [
    "Data Scientist", "Data Analytics",
    "Data Engineering", "Machine Learning",
    "Managerial", "Consultant"
]

data_science = "Data Science|NLP"
data_analyst = "Analysit|Analytics"
data_engineer = "Data Engineer|ETL|Architech|Infrastructure"
ml_engineer = "Machine Learning|ML|Big Data|AI"
manager = "Manager|Head|Director|Lead|Principal|Staff"
consultant="Consultant|Freelane"

conditions = [
    (salaries["Designation"].str.contains(data_science)),
    (salaries["Designation"].str.contains(data_analyst)),
    (salaries["Designation"].str.contains(data_engineer)),
    (salaries["Designation"].str.contains(ml_engineer)),
    (salaries["Designation"].str.contains(manager)),
    (salaries["Designation"].str.contains(consultant))
]

salaries["Job_Category"] = np.select(conditions, 
                                    job_categories,
                                    default="Other")


salaries[["Designation", "Job_Category"]].head()


# visializing job category frequency
sns.countplot(data=salaries, x="Job_Category", palette="tab10")
plt.show()











# Filter planes for columns that are of "object" data type.
non_numeric = planes.select_dtypes("object")
non_numeric


# Loop through the columns in the dataset.
for feature in non_numeric.columns:
    print(feature)


# Add the column iterator to the print statement, then call the function to return the number of unique values in the column.
for feature in non_numeric.columns:
    print(f"Number of unique values in {feature} column:", non_numeric[feature].nunique())








planes["Duration"].head()


# Create a list of categories containing "Short-haul", "Medium", and "Long-haul".
flight_categories = ["Short-haul", "Medium", "Long-haul"]


# Create short_flights, a string to capture values of "0h", "1h", "2h", "3h", or "4h" taking care to avoid values such as "10h".
#Â Create short-haul values
short_flights = "^0h|^1h|^2h|^3h|^4h"
planes["Duration"].str.contains(short_flights).value_counts()


# Create medium_flights to capture any values between five and nine hours.
medium_flights = "^5h|^6h|^7h|^8h|^9h"
planes["Duration"].str.contains(medium_flights).value_counts()


# Create long_flights to capture any values from 10 hours to 16 hours inclusive.
long_flights = "10h|11h|12h|13h|14h|15h|16h"
planes["Duration"].str.contains(long_flights).value_counts()








# Create conditions, a list containing subsets of planes["Duration"] based on short_flights, medium_flights, and long_flights.
conditions = [
    (planes["Duration"].str.contains(short_flights)),
    (planes["Duration"].str.contains(medium_flights)),
    (planes["Duration"].str.contains(long_flights))
]

planes["Duration_Category"] = np.select(conditions,
                                       flight_categories,
                                       default="Extreme duration")


# Create a plot showing the count of each category.
sns.countplot(data=planes, x="Duration_Category", palette="tab10")


planes["Duration"]






